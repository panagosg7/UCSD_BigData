{
 "metadata": {
  "name": "",
  "signature": "sha256:bf3c828f368f9cbdb93de4384d96ea247ae1aa4bc55a8ad8f0a9e6be120491af"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Compute Station Weights\n",
      "\n",
      "\n",
      "This module computes the *weight* of every station. In this setting, we define as *weight* $W$ \n",
      "of a station $S$, the total number of measurements that we have available for $S$. \n",
      "\n",
      "To calculate this number for each station $S$ we count the number of lines that correspond \n",
      "to $S$ in the input file `weather.csv`.\n",
      "\n",
      "We are using MapReduce to calculate this. The details of this job are very similar to the well-know\n",
      "example \"word-count\", so they are ommitted here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sklearn as sk\n",
      "print 'pandas version: ',pd.__version__\n",
      "print 'numpy version:',np.__version__\n",
      "print 'sklearn version:',sk.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pandas version:  0.13.1\n",
        "numpy version: 1.8.1\n",
        "sklearn version: 0.14.1\n"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "home_dir='/home/ubuntu/panagosg7'\n",
      "sys.path.append(home_dir+'/utils')\n",
      "from find_waiting_flow import *\n",
      "from AWS_keypair_management import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile weather_01.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "count the number of measurement for each year\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "class MRWeight(MRJob):\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        try:\n",
      "            self.increment_counter('MrJob Counters','mapper-all',1)\n",
      "            elements=line.split(',')             \n",
      "   \n",
      "            if elements[0]!='station':\n",
      "                out = (elements[0],1)\n",
      "            else:\n",
      "                out = None\n",
      "                \n",
      "#                         try:\n",
      "#             self.increment_counter('MrJob Counters','mapper-all',1)\n",
      "#             elements=line.split(',')\n",
      "   \n",
      "#             if elements[0]!='station':\n",
      "                \n",
      "#                 if elements[1] in ['TMIN','TMAX','PRCP']:\n",
      "                    \n",
      "#                     emp = elements.count('')\n",
      "#                     tot = len(elements) - 3\n",
      "                    \n",
      "#                     # more than 70% full\n",
      "#                     if float(emp)/tot < 0.3:\n",
      "#                         yield (elements[0],1)\n",
      "                    \n",
      "                     \n",
      "                \n",
      "                     \n",
      "        except Exception, e:\n",
      "            stderr.write('Error in line:\\n'+line)\n",
      "            stderr.write(e)\n",
      "            self.increment_counter('MrJob Counters','mapper-error',1)\n",
      "            out = None\n",
      "\n",
      "        finally:\n",
      "            if out != None:\n",
      "                pass\n",
      "            #yield out\n",
      "        \n",
      "    def combiner(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','combiner',1)\n",
      "        yield (word, sum(counts))\n",
      "\n",
      "    def reducer(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','reducer',1)\n",
      "        yield (word, sum(counts))      \n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    MRWeight.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting weather_01.py\n"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Output folder"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_dir = '/home/ubuntu/panagosg7/notebooks/weather.mapreduce/output/'\n",
      "!mkdir -p $output_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Running job inline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os.path\n",
      "\n",
      "local_data='/home/ubuntu/panagosg7/data/weather/ALL.head-1000.csv'\n",
      "\n",
      "local_count_file = os.path.join(output_dir,'counts.txt')\n",
      "!ls -l $local_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-rw-r-- 1 ubuntu ubuntu 858960 May 19 12:14 /home/ubuntu/panagosg7/data/weather/ALL.head-1000.csv\r\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python weather_01.py $local_data > $local_count_file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n",
        "creating tmp directory /tmp/weather_01.ubuntu.20140609.202124.370813\r\n",
        "writing to /tmp/weather_01.ubuntu.20140609.202124.370813/step-0-mapper_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  MrJob Counters:\r\n",
        "    mapper-all: 999\r\n",
        "writing to /tmp/weather_01.ubuntu.20140609.202124.370813/step-0-mapper-sorted\r\n",
        "> sort /tmp/weather_01.ubuntu.20140609.202124.370813/step-0-mapper_part-00000\r\n",
        "writing to /tmp/weather_01.ubuntu.20140609.202124.370813/step-0-reducer_part-00000\r\n",
        "Counters from step 1:\r\n",
        "  MrJob Counters:\r\n",
        "    mapper-all: 999\r\n",
        "Moving /tmp/weather_01.ubuntu.20140609.202124.370813/step-0-reducer_part-00000 -> /tmp/weather_01.ubuntu.20140609.202124.370813/output/part-00000\r\n",
        "Streaming final output from /tmp/weather_01.ubuntu.20140609.202124.370813/output\r\n",
        "removing tmp directory /tmp/weather_01.ubuntu.20140609.202124.370813\r\n"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Getting credentials for EMR"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "Creds= pickle.load(open('/home/ubuntu/Vault/Creds.pkl','rb'))\n",
      "print Creds.keys()\n",
      "print Creds['mrjob'].keys()\n",
      "pair=Creds['mrjob']\n",
      "key_id=pair['key_id']\n",
      "secret_key=pair['secret_key']\n",
      "ID=pair['ID']\n",
      "print ID,key_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['launcher', 'mrjob']\n",
        "['key_id', 'secret_key', 's3_logs', 'ID', 's3_scratch']\n",
        "EMR AKIAJAEGIABHWRAACKYA\n"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "job_flow_id=find_waiting_flow(key_id,secret_key)\n",
      "job_flow_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<boto.emr.emrobject.JobFlow object at 0x345bb90> no_script.yoavfreund.20140608.152022.140730 j-33E3A241PN05X WAITING\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 102,
       "text": [
        "u'j-33E3A241PN05X'"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Running on EMR"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "emr_count_file = output_dir + 'counts_emr.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#job_flow_id = 'j-2EYI61B8ITNL'\n",
      "\n",
      "#!python weather_01.py -r emr --emr-job-flow-id  $job_flow_id hdfs:/weather/weather.csv > $emr_count_file\n",
      "\n",
      "!python weather_01.py -r emr --emr-job-flow-id  $job_flow_id hdfs:/Weather.GHNC/ALL.csv_1024 > $emr_count_file\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/weather_01.ubuntu.20140609.203620.572522\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://pvekris.bucket/scratch/weather_01.ubuntu.20140609.203620.572522/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding our job to existing job flow j-33E3A241PN05X\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job on job flow j-33E3A241PN05X failed with status WAITING: Waiting after step failed\r\n",
        "Logs are in s3://yoav.hadoop/log/j-33E3A241PN05X/\r\n",
        "ec2_key_pair_file not specified, going to S3\r\n",
        "Scanning S3 logs for probable cause of failure\r\n",
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Attempting to terminate job...\r\n",
        "Traceback (most recent call last):\r\n",
        "  File \"weather_01.py\", line 62, in <module>\r\n",
        "    MRWeight.run()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/job.py\", line 494, in run\r\n",
        "    mr_job.execute()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/job.py\", line 512, in execute\r\n",
        "    super(MRJob, self).execute()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/launch.py\", line 147, in execute\r\n",
        "    self.run_job()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/launch.py\", line 213, in run_job\r\n",
        "    self.stdout.flush()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/runner.py\", line 614, in __exit__\r\n",
        "    self.cleanup()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/emr.py\", line 1010, in cleanup\r\n",
        "    super(EMRJobRunner, self).cleanup(mode=mode)\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/runner.py\", line 560, in cleanup\r\n",
        "    self._cleanup_job()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/emr.py\", line 1084, in _cleanup_job\r\n",
        "    self._opts['ec2_key_pair_file'])\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/ssh.py\", line 200, in ssh_terminate_single_job\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "    ssh_bin, address, ec2_key_pair_file, ['hadoop', 'job', '-list']))\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/ssh.py\", line 82, in ssh_run\r\n",
        "    p = Popen(args, stdout=PIPE, stderr=PIPE, stdin=PIPE)\r\n",
        "  File \"/home/ubuntu/anaconda/lib/python2.7/subprocess.py\", line 709, in __init__\r\n",
        "    errread, errwrite)\r\n",
        "  File \"/home/ubuntu/anaconda/lib/python2.7/subprocess.py\", line 1326, in _execute_child\r\n",
        "    raise child_exception\r\n",
        "TypeError: execv() arg 2 must contain only strings\r\n"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Read Stations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Read the stations information from `stations.pkl` into a Pandas Dataframe:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "stations_file='/home/ubuntu/panagosg7/notebooks/weather.mapreduce/stations.pkl'\n",
      "!ls -l $stations_file\n",
      "\n",
      "file=open(stations_file)\n",
      "stations_df=pickle.load(file)\n",
      "type(stations_df)\n",
      "stations_coords_df = stations_df.ix[:,['longitude', 'latitude']]\n",
      "\n",
      "stations_coords_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-rw-r-- 1 ubuntu ubuntu 8051413 May 20 21:51 /home/ubuntu/panagosg7/notebooks/weather.mapreduce/stations.pkl\r\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>longitude</th>\n",
        "      <th>latitude</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>ACW00011604</th>\n",
        "      <td>-61.7833</td>\n",
        "      <td> 17.1167</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ACW00011647</th>\n",
        "      <td>-61.7833</td>\n",
        "      <td> 17.1333</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AE000041196</th>\n",
        "      <td> 55.5170</td>\n",
        "      <td> 25.3330</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AF000040930</th>\n",
        "      <td> 69.0170</td>\n",
        "      <td> 35.3170</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AG000060390</th>\n",
        "      <td>  3.2500</td>\n",
        "      <td> 36.7167</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "             longitude  latitude\n",
        "ACW00011604   -61.7833   17.1167\n",
        "ACW00011647   -61.7833   17.1333\n",
        "AE000041196    55.5170   25.3330\n",
        "AF000040930    69.0170   35.3170\n",
        "AG000060390     3.2500   36.7167\n",
        "\n",
        "[5 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape(stations_coords_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "(85284, 2)"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Read the file that contains the **weight** for each station \n",
      "(that we calculated earlier with a MapReduce) into another \n",
      "Panda Dataframe:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "with open(emr_count_file) as f:\n",
      "    weight_df = pd.read_table(f, index_col=0, header=None, names = ['weight'] )\n",
      "\n",
      "weight_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>weight</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>AJ000037668</th>\n",
        "      <td>  28</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037679</th>\n",
        "      <td>  29</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037734</th>\n",
        "      <td>  56</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037756</th>\n",
        "      <td> 105</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037844</th>\n",
        "      <td> 110</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "             weight\n",
        "AJ000037668      28\n",
        "AJ000037679      29\n",
        "AJ000037734      56\n",
        "AJ000037756     105\n",
        "AJ000037844     110\n",
        "\n",
        "[5 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape(weight_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "(85283, 1)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Join station information on station id"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compute the join of each station with the longitude and latitude, so that we \n",
      "get a dataframe that combines the weight and coordinates of each station."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weighted_stations = weight_df.join(stations_coords_df)\n",
      "weighted_stations.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>weight</th>\n",
        "      <th>longitude</th>\n",
        "      <th>latitude</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>AJ000037668</th>\n",
        "      <td>  28</td>\n",
        "      <td> 47.500</td>\n",
        "      <td> 41.100</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037679</th>\n",
        "      <td>  29</td>\n",
        "      <td> 49.200</td>\n",
        "      <td> 41.100</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037734</th>\n",
        "      <td>  56</td>\n",
        "      <td> 46.000</td>\n",
        "      <td> 40.800</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037756</th>\n",
        "      <td> 105</td>\n",
        "      <td> 48.933</td>\n",
        "      <td> 40.533</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037844</th>\n",
        "      <td> 110</td>\n",
        "      <td> 48.167</td>\n",
        "      <td> 40.333</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 3 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "             weight  longitude  latitude\n",
        "AJ000037668      28     47.500    41.100\n",
        "AJ000037679      29     49.200    41.100\n",
        "AJ000037734      56     46.000    40.800\n",
        "AJ000037756     105     48.933    40.533\n",
        "AJ000037844     110     48.167    40.333\n",
        "\n",
        "[5 rows x 3 columns]"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape(weighted_stations)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "(85283, 3)"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Store the station information in a pickled file to be used later"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gzip\n",
      "f = gzip.open('weighted_stations.pklz','wb')\n",
      "pickle.dump(weighted_stations,f)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    }
   ],
   "metadata": {}
  }
 ]
}