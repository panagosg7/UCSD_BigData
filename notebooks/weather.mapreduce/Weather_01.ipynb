{
 "metadata": {
  "name": "",
  "signature": "sha256:f7ea71d5f1b4cdf24e9ac85fc9c931abd476a6be2adbaf4d6ea664943bffefb0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2. Hierarchical partition"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sklearn as sk\n",
      "print 'pandas version: ',pd.__version__\n",
      "print 'numpy version:',np.__version__\n",
      "print 'sklearn version:',sk.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pandas version:  0.13.1\n",
        "numpy version: 1.8.1\n",
        "sklearn version: 0.14.1\n"
       ]
      }
     ],
     "prompt_number": 314
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "home_dir='/home/ubuntu/panagosg7'\n",
      "sys.path.append(home_dir+'/utils')\n",
      "from find_waiting_flow import *\n",
      "from AWS_keypair_management import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 315
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile weather_01.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "count the number of measurement for each year\n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "# Temporarily disable this\n",
      "# cat='TMAX'\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        try:\n",
      "            self.increment_counter('MrJob Counters','mapper-all',1)\n",
      "            elements=line.split(',')\n",
      "            \n",
      "            #if elements[0]!='station' and elements[1]==cat:\n",
      "            \n",
      "            # Take all measurements into account!\n",
      "            if elements[0]!='station':\n",
      "                #out = (None, elements)\n",
      "                #self.increment_counter('MrJob Counters for ' + cat, elements[0],1)\n",
      "                out = (elements[0],1)\n",
      "            else:\n",
      "                out = None\n",
      "                     \n",
      "        except Exception, e:\n",
      "            stderr.write('Error in line:\\n'+line)\n",
      "            stderr.write(e)\n",
      "            self.increment_counter('MrJob Counters','mapper-error',1)\n",
      "            out = None # ('error',(1,1))\n",
      "\n",
      "        finally:\n",
      "            if out != None:\n",
      "                yield out\n",
      "        \n",
      "    def combiner(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','combiner',1)\n",
      "        yield (word, sum(counts))\n",
      "\n",
      "    def reducer(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','reducer',1)\n",
      "        yield (word, sum(counts))\n",
      "        \n",
      "        \n",
      "\n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting weather_01.py\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Output folder"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_dir = '/home/ubuntu/panagosg7/notebooks/weather.mapreduce/output/'\n",
      "!mkdir -p $output_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Running job inline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os.path\n",
      "\n",
      "local_data='/home/ubuntu/panagosg7/data/weather/ALL.head-1000.csv'\n",
      "\n",
      "local_count_file = os.path.join(output_dir,'counts.txt')\n",
      "!ls -l $local_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-rw-r-- 1 ubuntu ubuntu 858960 May 19 12:14 /home/ubuntu/panagosg7/data/weather/ALL.head-1000.csv\r\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python weather_01.py $local_data > $local_count_file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n",
        "creating tmp directory /tmp/weather_01.ubuntu.20140520.172919.453454\r\n",
        "writing to /tmp/weather_01.ubuntu.20140520.172919.453454/step-0-mapper_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  MrJob Counters:\r\n",
        "    combiner: 11\r\n",
        "    mapper-all: 999\r\n",
        "writing to /tmp/weather_01.ubuntu.20140520.172919.453454/step-0-mapper-sorted\r\n",
        "> sort /tmp/weather_01.ubuntu.20140520.172919.453454/step-0-mapper_part-00000\r\n",
        "writing to /tmp/weather_01.ubuntu.20140520.172919.453454/step-0-reducer_part-00000\r\n",
        "Counters from step 1:\r\n",
        "  MrJob Counters:\r\n",
        "    combiner: 11\r\n",
        "    mapper-all: 999\r\n",
        "    reducer: 11\r\n",
        "Moving /tmp/weather_01.ubuntu.20140520.172919.453454/step-0-reducer_part-00000 -> /tmp/weather_01.ubuntu.20140520.172919.453454/output/part-00000\r\n",
        "Streaming final output from /tmp/weather_01.ubuntu.20140520.172919.453454/output\r\n",
        "removing tmp directory /tmp/weather_01.ubuntu.20140520.172919.453454\r\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Running on EMR"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "Creds= pickle.load(open('/home/ubuntu/Vault/Creds.pkl','rb'))\n",
      "print Creds.keys()\n",
      "print Creds['mrjob'].keys()\n",
      "pair=Creds['mrjob']\n",
      "key_id=pair['key_id']\n",
      "secret_key=pair['secret_key']\n",
      "ID=pair['ID']\n",
      "print ID,key_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "job_flow_id=find_waiting_flow(key_id,secret_key)\n",
      "job_flow_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<boto.emr.emrobject.JobFlow object at 0x5cb3910> no_script.yoavfreund.20140516.040032.370095 j-262J0JTFJIRLO WAITING\n",
        "<boto.emr.emrobject.JobFlow object at 0x5ee8c90> no_script.yoavfreund.20140517.080731.371759 j-1RE8D7HBISOI0 WAITING\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 301,
       "text": [
        "u'j-1RE8D7HBISOI0'"
       ]
      }
     ],
     "prompt_number": 301
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "emr_count_file = output_dir + 'counts_emr.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 302
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python weather_01.py -r emr --emr-job-flow-id  $job_flow_id hdfs:/weather/weather.csv > $emr_count_file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/weather_01.ubuntu.20140521.035531.974467\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://pvekris.bucket/scratch/weather_01.ubuntu.20140521.035531.974467/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding our job to existing job flow j-1RE8D7HBISOI0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 30.5s ago, status RUNNING: Running step (weather_01.ubuntu.20140521.035531.974467: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 61.1s ago, status RUNNING: Running step (weather_01.ubuntu.20140521.035531.974467: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 91.6s ago, status RUNNING: Running step (weather_01.ubuntu.20140521.035531.974467: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 122.1s ago, status RUNNING: Running step (weather_01.ubuntu.20140521.035531.974467: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 152.6s ago, status RUNNING: Running step (weather_01.ubuntu.20140521.035531.974467: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 183.1s ago, status RUNNING: Running step (weather_01.ubuntu.20140521.035531.974467: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job completed.\r\n",
        "Running time was 141.0s (not counting time spent waiting for the EC2 instances)\r\n",
        "ec2_key_pair_file not specified, going to S3\r\n",
        "Fetching counters from S3...\r\n",
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  File Input Format Counters :\r\n",
        "    Bytes Read: 7670788923\r\n",
        "  File Output Format Counters :\r\n",
        "    Bytes Written: 1462822\r\n",
        "  FileSystemCounters:\r\n",
        "    FILE_BYTES_READ: 779082\r\n",
        "    FILE_BYTES_WRITTEN: 3715013\r\n",
        "    HDFS_BYTES_READ: 7670794863\r\n",
        "    S3_BYTES_WRITTEN: 1462822\r\n",
        "  Job Counters :\r\n",
        "    Data-local map tasks: 60\r\n",
        "    Launched map tasks: 63\r\n",
        "    Launched reduce tasks: 11\r\n",
        "    Rack-local map tasks: 3\r\n",
        "    SLOTS_MILLIS_MAPS: 2564137\r\n",
        "    SLOTS_MILLIS_REDUCES: 320861\r\n",
        "    Total time spent by all maps waiting after reserving slots (ms): 0\r\n",
        "    Total time spent by all reduces waiting after reserving slots (ms): 0\r\n",
        "  Map-Reduce Framework:\r\n",
        "    CPU time spent (ms): 1231690\r\n",
        "    Combine input records: 9358394\r\n",
        "    Combine output records: 85341\r\n",
        "    Map input bytes: 7668890105\r\n",
        "    Map input records: 9358395\r\n",
        "    Map output bytes: 149734304\r\n",
        "    Map output materialized bytes: 1053234\r\n",
        "    Map output records: 9358394\r\n",
        "    Physical memory (bytes) snapshot: 29635145728\r\n",
        "    Reduce input groups: 85283\r\n",
        "    Reduce input records: 85341\r\n",
        "    Reduce output records: 85283\r\n",
        "    Reduce shuffle bytes: 1053234\r\n",
        "    SPLIT_RAW_BYTES: 5940\r\n",
        "    Spilled Records: 170682\r\n",
        "    Total committed heap usage (bytes): 28128575488\r\n",
        "    Virtual memory (bytes) snapshot: 127113330688\r\n",
        "  MrJob Counters:\r\n",
        "    mapper-all: 9358395\r\n",
        "    reducer: 85283\r\n",
        "Streaming final output from s3://pvekris.bucket/scratch/weather_01.ubuntu.20140521.035531.974467/output/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing tmp directory /tmp/weather_01.ubuntu.20140521.035531.974467\r\n",
        "Removing all files in s3://pvekris.bucket/scratch/weather_01.ubuntu.20140521.035531.974467/\r\n"
       ]
      }
     ],
     "prompt_number": 303
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Read Stations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Read the stations information into a Pandas Dataframe:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "stations_file='/home/ubuntu/panagosg7/notebooks/weather.mapreduce/stations.pkl'\n",
      "!ls -l $stations_file\n",
      "\n",
      "file=open(stations_file)\n",
      "stations_df=pickle.load(file)\n",
      "type(stations_df)\n",
      "stations_coords_df = stations_df.ix[:,['longitude', 'latitude']]\n",
      "\n",
      "stations_coords_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-rw-r-- 1 ubuntu ubuntu 8051413 May 15 12:21 /home/ubuntu/panagosg7/notebooks/weather.mapreduce/stations.pkl\r\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>longitude</th>\n",
        "      <th>latitude</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>ACW00011604</th>\n",
        "      <td>-61.7833</td>\n",
        "      <td> 17.1167</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ACW00011647</th>\n",
        "      <td>-61.7833</td>\n",
        "      <td> 17.1333</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AE000041196</th>\n",
        "      <td> 55.5170</td>\n",
        "      <td> 25.3330</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AF000040930</th>\n",
        "      <td> 69.0170</td>\n",
        "      <td> 35.3170</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AG000060390</th>\n",
        "      <td>  3.2500</td>\n",
        "      <td> 36.7167</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "             longitude  latitude\n",
        "ACW00011604   -61.7833   17.1167\n",
        "ACW00011647   -61.7833   17.1333\n",
        "AE000041196    55.5170   25.3330\n",
        "AF000040930    69.0170   35.3170\n",
        "AG000060390     3.2500   36.7167\n",
        "\n",
        "[5 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape(stations_coords_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "(85284, 2)"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# # This is how to create an array out these:\n",
      "# ix = ALL_Stations.index.values\n",
      "# ix = ix.reshape(len(ix),1)\n",
      "# coords = np.hstack((ix,ll))\n",
      "\n",
      "# # Sort by longitude\n",
      "# coords = coords[coords[:,1].argsort()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Read the file that contains the **count** for each station into another Panda Dataframe:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "with open(emr_count_file) as f:\n",
      "    weight_df = pd.read_table(f, index_col=0, header=None, names = ['weight'] )\n",
      "\n",
      "weight_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>weight</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>AJ000037668</th>\n",
        "      <td>  28</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037679</th>\n",
        "      <td>  29</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037734</th>\n",
        "      <td>  56</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037756</th>\n",
        "      <td> 105</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037844</th>\n",
        "      <td> 110</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 82,
       "text": [
        "             weight\n",
        "AJ000037668      28\n",
        "AJ000037679      29\n",
        "AJ000037734      56\n",
        "AJ000037756     105\n",
        "AJ000037844     110\n",
        "\n",
        "[5 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape(weight_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 83,
       "text": [
        "(85283, 1)"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compute the join of each station with the longitude and latitude."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stations = weight_df.join(stations_coords_df)\n",
      "stations.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>weight</th>\n",
        "      <th>longitude</th>\n",
        "      <th>latitude</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>AJ000037668</th>\n",
        "      <td>  28</td>\n",
        "      <td> 47.500</td>\n",
        "      <td> 41.100</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037679</th>\n",
        "      <td>  29</td>\n",
        "      <td> 49.200</td>\n",
        "      <td> 41.100</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037734</th>\n",
        "      <td>  56</td>\n",
        "      <td> 46.000</td>\n",
        "      <td> 40.800</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037756</th>\n",
        "      <td> 105</td>\n",
        "      <td> 48.933</td>\n",
        "      <td> 40.533</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037844</th>\n",
        "      <td> 110</td>\n",
        "      <td> 48.167</td>\n",
        "      <td> 40.333</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 3 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 238,
       "text": [
        "             weight  longitude  latitude\n",
        "AJ000037668      28     47.500    41.100\n",
        "AJ000037679      29     49.200    41.100\n",
        "AJ000037734      56     46.000    40.800\n",
        "AJ000037756     105     48.933    40.533\n",
        "AJ000037844     110     48.167    40.333\n",
        "\n",
        "[5 rows x 3 columns]"
       ]
      }
     ],
     "prompt_number": 238
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape(stations)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 155,
       "text": [
        "(85283, 3)"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Station partitioning #1 (fixed 2-level)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# latitude groups\n",
      "la_groups   = 10\n",
      "\n",
      "# total number of measurements\n",
      "tot_weight = sum(stations['weight'])\n",
      "\n",
      "# number of measurements in each latitude group (band)\n",
      "la_width = ceil(tot_weight/la_groups)+1\n",
      "\n",
      "# Sort by latitude so that stations are grouped \n",
      "lat_sorted_stations = stations.sort('latitude')\n",
      "\n",
      "# Compute a new column with the cummulative count of \n",
      "lat_sorted_stations['cum_lat_weight'] = lat_sorted_stations['weight'].cumsum()\n",
      "\n",
      "lat_sorted_stations['la_group'] = floor(lat_sorted_stations['cum_lat_weight'] / la_width)\n",
      "\n",
      "lat_grouped_stations = lat_sorted_stations.groupby(['la_group'])\n",
      "\n",
      "# As we can see we have splitted the stations in groups of\n",
      "# approximately the same number of measurements\n",
      "print lat_grouped_stations['weight'].sum()\n",
      "\n",
      "# Also interesting statistics:\n",
      "#lat_grouped_stations['weight'].describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "la_group\n",
        "0           935821\n",
        "1           935741\n",
        "2           935902\n",
        "3           935694\n",
        "4           934975\n",
        "5           936310\n",
        "6           936424\n",
        "7           935851\n",
        "8           935787\n",
        "9           935889\n",
        "Name: weight, dtype: int64\n"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for lat_id, group  in lat_grouped_stations:\n",
      "    \n",
      "    print\n",
      "    print \"-----------------------------\"\n",
      "    print 'lat_group', lat_id\n",
      "    print \"-----------------------------\"\n",
      "    \n",
      "    # longitude groups\n",
      "    lo_groups   = 10                         \n",
      "    \n",
      "    # total number of measurements\n",
      "    tot_weight = sum(group['weight'])    \n",
      "    \n",
      "    # number of measurements in each latitude group (band)\n",
      "    lo_width = ceil(tot_weight/lo_groups)+1\n",
      "\n",
      "    # Sort by latitude so that stations are grouped \n",
      "    lon_sorted_stations = group.sort('longitude')\n",
      "    \n",
      "    # Compute a new column with the cummulative count of \n",
      "    lon_sorted_stations['cum_lon_weight'] = lon_sorted_stations['weight'].cumsum()\n",
      "\n",
      "    lon_sorted_stations['lo_group'] = floor(lon_sorted_stations['cum_lon_weight'] / lo_width)\n",
      "\n",
      "    lon_grouped_stations = lon_sorted_stations.groupby(['lo_group'])\n",
      "\n",
      "    print lon_grouped_stations['weight'].sum()\n",
      "        \n",
      "    #print group"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-----------------------------\n",
        "lat_group 0.0\n",
        "-----------------------------\n",
        "lo_group\n",
        "0           93528\n",
        "1           93604\n",
        "2           93550\n",
        "3           93319\n",
        "4           93794\n",
        "5           93622\n",
        "6           93412\n",
        "7           93827\n",
        "8           93446\n",
        "9           93719\n",
        "Name: counts, dtype: int64\n",
        "\n",
        "-----------------------------\n",
        "lat_group 1.0\n",
        "-----------------------------\n",
        "lo_group\n",
        "0           93569\n",
        "1           93554\n",
        "2           93556\n",
        "3           93588\n",
        "4           93596\n",
        "5           93569\n",
        "6           93578\n",
        "7           93560\n",
        "8           93551\n",
        "9           93620\n",
        "Name: counts, dtype: int64\n",
        "\n",
        "-----------------------------\n",
        "lat_group 2.0\n",
        "-----------------------------\n",
        "lo_group\n",
        "0           93063\n",
        "1           93464\n",
        "2           93376\n",
        "3           94062\n",
        "4           93752\n",
        "5           93286\n",
        "6           93742\n",
        "7           93524\n",
        "8           94004\n",
        "9           93629\n",
        "Name: counts, dtype: int64\n",
        "\n",
        "-----------------------------\n",
        "lat_group 3.0\n",
        "-----------------------------\n",
        "lo_group\n",
        "0           93370\n",
        "1           93250\n",
        "2           93989\n",
        "3           93594\n",
        "4           93439\n",
        "5           93433\n",
        "6           93912\n",
        "7           92837\n",
        "8           93692\n",
        "9           94178\n",
        "Name: counts, dtype: int64\n",
        "\n",
        "-----------------------------\n",
        "lat_group 4.0\n",
        "-----------------------------\n",
        "lo_group\n",
        "0           92964\n",
        "1           93703\n",
        "2           93822\n",
        "3           93391\n",
        "4           92737\n",
        "5           94143\n",
        "6           93575\n",
        "7           93637\n",
        "8           93460\n",
        "9           93543\n",
        "Name: counts, dtype: int64\n",
        "\n",
        "-----------------------------\n",
        "lat_group 5.0\n",
        "-----------------------------\n",
        "lo_group\n",
        "0           93542\n",
        "1           93584\n",
        "2           93170\n",
        "3           94225\n",
        "4           93304\n",
        "5           93137\n",
        "6           93644\n",
        "7           93482\n",
        "8           94252\n",
        "9           93970\n",
        "Name: counts, dtype: int64\n",
        "\n",
        "-----------------------------\n",
        "lat_group 6.0\n",
        "-----------------------------\n",
        "lo_group\n",
        "0           93495\n",
        "1           93556\n",
        "2           93062\n",
        "3           94328\n",
        "4           93186\n",
        "5           94230\n",
        "6           93498\n",
        "7           93182\n",
        "8           94248\n",
        "9           93639\n",
        "Name: counts, dtype: int64"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "-----------------------------\n",
        "lat_group 7.0\n",
        "-----------------------------\n",
        "lo_group\n",
        "0           93540\n",
        "1           93614\n",
        "2           93460\n",
        "3           93314\n",
        "4           93760\n",
        "5           93588\n",
        "6           93672\n",
        "7           93642\n",
        "8           93430\n",
        "9           93831\n",
        "Name: counts, dtype: int64\n",
        "\n",
        "-----------------------------\n",
        "lat_group 8.0\n",
        "-----------------------------\n",
        "lo_group\n",
        "0           93481\n",
        "1           93042\n",
        "2           94203\n",
        "3           93539\n",
        "4           93029\n",
        "5           93781\n",
        "6           93132\n",
        "7           94331\n",
        "8           92934\n",
        "9           94315\n",
        "Name: counts, dtype: int64\n",
        "\n",
        "-----------------------------\n",
        "lat_group 9.0\n",
        "-----------------------------\n",
        "lo_group\n",
        "0           93092\n",
        "1           93832\n",
        "2           93821\n",
        "3           93281\n",
        "4           93850\n",
        "5           93601\n",
        "6           93600\n",
        "7           93498\n",
        "8           93714\n",
        "9           93600\n",
        "Name: counts, dtype: int64\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Station partitioning #2 (Multi-level)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_group_info(levels):\n",
      "    columns = ['west', 'east', 'south', 'north']\n",
      "    index = range(0,2**levels)\n",
      "    return pd.DataFrame(index=index, columns=columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 299
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class HierarchicalIndexing:\n",
      "    \n",
      "    _orig_df    = None\n",
      "    _levels     = 0\n",
      "    _output_df  = None\n",
      "    _groups     = None\n",
      "    _groups_lst = []\n",
      "    _computed   = False\n",
      "    \n",
      "    \n",
      "    def __init__(self, df, levels):\n",
      "        \"\"\"\n",
      "        Initializer\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        df    : Pandas.DataFrame\n",
      "                Indexed by station ID\n",
      "                Required fields:\n",
      "                 * weight\n",
      "                 * longitude\n",
      "                 * latitude\n",
      "\n",
      "        level : int\n",
      "                  Level of iteration - reasonable values are > 0 \n",
      "        \"\"\"        \n",
      "        \n",
      "        # initialize a dataframe that will hold data regarding the created groups \n",
      "        columns       = ['west', 'east', 'south', 'north']\n",
      "        index         = range(0,2**levels)\n",
      "        self._groups  = pd.DataFrame(index=index, columns=columns)\n",
      "        \n",
      "        # set level\n",
      "        self._levels = levels\n",
      "        \n",
      "        # keep a copy of the original input dataframe\n",
      "        self._orig_df = df\n",
      "\n",
      "\n",
      "    def getGroups(self):\n",
      "        if not self._computed:\n",
      "            self._groups_lst = []\n",
      "            self.run()\n",
      "        return self._groups_lst\n",
      "\n",
      "    \n",
      "    def getOutputDF(self):\n",
      "        if not self._computed:\n",
      "            self.run()\n",
      "        return self._output_df\n",
      "\n",
      "    \n",
      "    def next_c(self,c):\n",
      "        if   c == 'longitude':\n",
      "            return 'latitude'\n",
      "        elif c == 'latitude':\n",
      "            return 'longitude'\n",
      "        else:\n",
      "            raise Exception('long/lat')\n",
      "\n",
      "            \n",
      "    def level_str(self,i):\n",
      "        return 'g' + str(i)\n",
      "\n",
      "    \n",
      "    def run(self):        \n",
      "        if not self._computed:\n",
      "            # make a deep copy every time `run` is called\n",
      "            self._output_df = self.__run__(self._orig_df.copy(deep=True), self._levels)\n",
      "            self._computed  = True            \n",
      "\n",
      "    def path_to_key(self, a): \n",
      "        return sum([ x * (2**i) for (x,i) in zip(a, range(0, len(a)))])\n",
      "            \n",
      "        \n",
      "    def __run__(self, df, level, coord='longitude', west=-180, east=180, south=-90, north=90, path=[]):\n",
      "        \"\"\"\n",
      "        __run__\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        df      : Pandas.DataFrame\n",
      "                  \n",
      "        level   : int\n",
      "                  Level of iteration\n",
      "\n",
      "        coord   : str\n",
      "                  'longitide' or 'latitude'\n",
      "\n",
      "        east    : int\n",
      "                  the eastern boundary of the region\n",
      "\n",
      "        west    : int\n",
      "                  the western boundary of the region\n",
      "\n",
      "        north   : int\n",
      "                  the northern boundary of the region\n",
      "\n",
      "        south   : int\n",
      "                  the southern boundary of the region\n",
      "\n",
      "\n",
      "               if coord = 'longitude':\n",
      "\n",
      "                       north\n",
      "              ______________________________\n",
      "             |FALSE                 |   TRUE|   (90)\n",
      "             |               new -> |       |\n",
      "        west |             boundary |       | east\n",
      "             |                      |       | \n",
      "             |______________________|_______|   (-90) \n",
      "           (-180)       south             (180)   \n",
      "\n",
      "\n",
      "                if coord = 'latitude':      \n",
      "\n",
      "                       north\n",
      "              _______________________\n",
      "             |TRUE           new     |  (90)\n",
      "             |             boundary  |\n",
      "        west |                |      | east\n",
      "             |________________v______|\n",
      "             |FALSE                  |\n",
      "             |                       |\n",
      "             |_______________________|  (-90) \n",
      "           (-180)       south      (180)   \n",
      "\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        A new dataframe containing the columns of the original dataframe,\n",
      "        extended with columns g1, g2, ... that altogether denote the group\n",
      "        that each station belongs to.\n",
      "        \"\"\"\n",
      "        \n",
      "        if level < 0:\n",
      "            # add boundaries\n",
      "            df['north'] = north\n",
      "            df['south'] = south\n",
      "            df['east'] = east\n",
      "            df['west'] = west\n",
      "            \n",
      "            \n",
      "            \n",
      "            idx = self.path_to_key(path)\n",
      "            \n",
      "            self._groups_lst.append((path,north,south,east,west))           \n",
      "                        \n",
      "            return df\n",
      "\n",
      "        # sort by coord\n",
      "\n",
      "        # Sort by latitude so that stations are grouped \n",
      "        df = df.sort(coord)\n",
      "\n",
      "        # Compute a new column with the cummulative count of \n",
      "        df['cum_weight'] = df['weight'].cumsum()\n",
      "\n",
      "        # compute the threshold of weight (the point that designates the meridian)\n",
      "        threshold = df['weight'].sum() / 2\n",
      "\n",
      "        # group index column\n",
      "        gi = self.level_str(level)\n",
      "\n",
      "        # assign a group number based on weight\n",
      "        df[gi] = df['cum_weight'] > threshold\n",
      "\n",
      "        # drop the 'cum_weight' column\n",
      "        del df['cum_weight']\n",
      "\n",
      "        # break down into groups based on the grouping column\n",
      "        gdf = df.groupby([gi])\n",
      "\n",
      "        # ugly way to get the boundary of the partition on the coordinate of interest\n",
      "        new_boundary = np.average([[group[coord].max() for name, group in gdf if name==False][0], \\\n",
      "                                   [group[coord].min() for name, group in gdf if name==True ][0]])\n",
      "\n",
      "        # recursively partition the groups\n",
      "        children = []      \n",
      "\n",
      "        for name, child in gdf:\n",
      "\n",
      "            if name==False: \n",
      "                # cum_weight is smaller than threshold, i.e.\n",
      "                #   - station is west of the median if it's longitude, so east gets updated\n",
      "                #   - station is south of the median if it's latitude, so north gets updated\n",
      "                if coord=='longitude':\n",
      "                    east = new_boundary\n",
      "                else:\n",
      "                    north = new_boundary\n",
      "            else:            \n",
      "                # cum_weight is greater than threshold, i.e.\n",
      "                #   - station is east of the median if it's longitude, so west gets updated\n",
      "                #   - station is north of the median if it's latitude, so south gets updated\n",
      "                if coord=='longitude':\n",
      "                    west = new_boundary\n",
      "                else:\n",
      "                    south = new_boundary\n",
      "\n",
      "            # do the recursive call using updates boundaries\n",
      "            # ignore_index = True\n",
      "\n",
      "            children.append(self.__run__(child,level-1,self.next_c(coord),east,west,south,north,[int(name)]+path))\n",
      "\n",
      "        # concatenate children and return\n",
      "        return pd.concat(children)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 347
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_levels = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 348
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hi = HierarchicalIndexing(stations, num_levels)\n",
      "\n",
      "grouped_stations = hi.getOutputDF()\n",
      "\n",
      "grouped_stations.head()\n",
      "\n",
      "hi.getGroups()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 349,
       "text": [
        "[([0, 0], 40.134450000000001, -90, -87.533299999999997, -180),\n",
        " ([1, 0], 40.134450000000001, 40.134450000000001, -87.533299999999997, -180),\n",
        " ([0, 1], 34.883299999999998, -90, -87.533299999999997, -87.533299999999997),\n",
        " ([1, 1],\n",
        "  34.883299999999998,\n",
        "  34.883299999999998,\n",
        "  -87.533299999999997,\n",
        "  -87.533299999999997)]"
       ]
      }
     ],
     "prompt_number": 349
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stations.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>weight</th>\n",
        "      <th>longitude</th>\n",
        "      <th>latitude</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>AJ000037668</th>\n",
        "      <td>  28</td>\n",
        "      <td> 47.500</td>\n",
        "      <td> 41.100</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037679</th>\n",
        "      <td>  29</td>\n",
        "      <td> 49.200</td>\n",
        "      <td> 41.100</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037734</th>\n",
        "      <td>  56</td>\n",
        "      <td> 46.000</td>\n",
        "      <td> 40.800</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037756</th>\n",
        "      <td> 105</td>\n",
        "      <td> 48.933</td>\n",
        "      <td> 40.533</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AJ000037844</th>\n",
        "      <td> 110</td>\n",
        "      <td> 48.167</td>\n",
        "      <td> 40.333</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 3 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 295,
       "text": [
        "             weight  longitude  latitude\n",
        "AJ000037668      28     47.500    41.100\n",
        "AJ000037679      29     49.200    41.100\n",
        "AJ000037734      56     46.000    40.800\n",
        "AJ000037756     105     48.933    40.533\n",
        "AJ000037844     110     48.167    40.333\n",
        "\n",
        "[5 rows x 3 columns]"
       ]
      }
     ],
     "prompt_number": 295
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grouped_stations.groupby(['g' + str(i) for i in range(0, num_levels+1)] + ['north','south','east','west'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 298,
       "text": [
        "<pandas.core.groupby.DataFrameGroupBy object at 0x5a76e90>"
       ]
      }
     ],
     "prompt_number": 298
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stations['latitude'].max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 226,
       "text": [
        "82.516999999999996"
       ]
      }
     ],
     "prompt_number": 226
    }
   ],
   "metadata": {}
  }
 ]
}